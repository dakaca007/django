import requests
from datetime import datetime, timedelta
import os
import time
import json
import random
from bs4 import BeautifulSoup, SoupStrainer
import concurrent.futures
from functools import lru_cache
import threading
import queue
import tempfile
import shutil
import math

# é…ç½®é¡¹
START_ID = 1
END_ID = 2060020
INITIAL_DATE_RANGE = (datetime(2010, 1, 1), datetime(2025, 12, 31))  # åˆå§‹æ—¥æœŸæœç´¢èŒƒå›´
PROGRESS_JSON = "progress.json"
FAILED_FILE = "failed.txt"
SONGS_META_FILE = "songs_meta.json"
BATCH_SIZE = 20
MAX_WORKERS = 5
MAX_RETRIES = 3
MAX_DATE_SHIFT = 14  # æ‰©å¤§æ—¥æœŸåç§»èŒƒå›´
AUTO_DETECT_SAMPLES = 10  # è‡ªåŠ¨æ¢æµ‹æ—¶æµ‹è¯•çš„æ ·æœ¬æ•°

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
session = requests.Session()
session.headers.update(HEADERS)

# çº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œå­˜æ”¾å¾…å†™å…¥çš„å…ƒæ•°æ®
meta_queue = queue.Queue()

def load_progress():
    if os.path.exists(PROGRESS_JSON):
        try:
            with open(PROGRESS_JSON, "r", encoding="utf-8") as f:
                data = json.load(f)
            sid = int(data.get("song_id", START_ID))
            ldate = datetime.fromisoformat(data.get("last_date", INITIAL_DATE_RANGE[0].isoformat()))
            return sid, ldate
        except Exception:
            print("âš ï¸ è¿›åº¦æ–‡ä»¶æŸåï¼Œé‡ç½®è¿›åº¦")
    return None, None  # è¿”å›Noneè¡¨ç¤ºéœ€è¦è‡ªåŠ¨æ¢æµ‹

def save_progress(song_id, last_date):
    try:
        with open(PROGRESS_JSON, "w", encoding="utf-8") as f:
            json.dump({
                "song_id": song_id,
                "last_date": last_date.date().isoformat()
            }, f)
    except Exception as e:
        print(f"âŒ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

def auto_detect_start_params():
    """è‡ªåŠ¨æ¢æµ‹æœ‰æ•ˆçš„èµ·å§‹IDå’Œæ—¥æœŸ"""
    print("ğŸ” å¼€å§‹è‡ªåŠ¨æ¢æµ‹æœ‰æ•ˆçš„èµ·å§‹å‚æ•°...")
    
    def test_params(song_id, test_date):
        """æµ‹è¯•å•ä¸ªå‚æ•°ç»„åˆ"""
        mp3_url, _ = find_mp3_url(song_id, test_date)
        return mp3_url is not None
    
    # åœ¨IDèŒƒå›´å†…éšæœºé€‰æ‹©æ ·æœ¬
    test_ids = random.sample(range(START_ID, END_ID), min(AUTO_DETECT_SAMPLES, END_ID-START_ID))
    
    # åœ¨æ—¥æœŸèŒƒå›´å†…ç”Ÿæˆå€™é€‰æ—¥æœŸ
    date_range = (INITIAL_DATE_RANGE[1] - INITIAL_DATE_RANGE[0]).days
    test_dates = [INITIAL_DATE_RANGE[0] + timedelta(days=random.randint(0, date_range)) 
                 for _ in range(AUTO_DETECT_SAMPLES)]
    
    # å¹¶è¡Œæµ‹è¯•æ‰€æœ‰ç»„åˆ
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = []
        for song_id in test_ids:
            for test_date in test_dates:
                futures.append(executor.submit(test_params, song_id, test_date))
        
        # ç­‰å¾…ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
        for future in concurrent.futures.as_completed(futures):
            if future.result():
                song_id = futures[0].args[0]  # è·å–æˆåŠŸçš„song_id
                test_date = futures[0].args[1]  # è·å–æˆåŠŸçš„test_date
                print(f"âœ… æ¢æµ‹åˆ°æœ‰æ•ˆå‚æ•° - ID: {song_id}, æ—¥æœŸ: {test_date.date()}")
                return song_id, test_date
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼å¹¶æ‰©å¤§æ—¥æœŸèŒƒå›´
    print("âš ï¸ è‡ªåŠ¨æ¢æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
    return START_ID, INITIAL_DATE_RANGE[0]

def find_mp3_url(song_id, base_date):
    """æ”¹è¿›çš„MP3æŸ¥æ‰¾å‡½æ•°ï¼Œæ”¯æŒåŠ¨æ€æ—¥æœŸèŒƒå›´"""
    base = "https://music.jsbaidu.com/upload/128"
    
    # åŠ¨æ€è°ƒæ•´æ—¥æœŸèŒƒå›´ï¼ŒåŸºäºsong_idçš„å“ˆå¸Œå€¼å¼•å…¥ä¸€äº›éšæœºæ€§
    date_shift = MAX_DATE_SHIFT + (song_id % 7)  # åœ¨MAX_DATE_SHIFTåŸºç¡€ä¸Šå¢åŠ 0-6å¤©
    
    # ç”Ÿæˆæ—¥æœŸåºåˆ—ï¼ŒåŒ…æ‹¬å‘å‰å’Œå‘åæœç´¢
    dates = [base_date + timedelta(days=i) for i in range(-date_shift//2, date_shift//2 + 1)]
    random.shuffle(dates)  # éšæœºåŒ–æœç´¢é¡ºåº
    
    with concurrent.futures.ThreadPoolExecutor() as ex:
        futures = {
            ex.submit(url_exists, f"{base}/{d:%Y/%m/%d}/{song_id}.mp3"): d
            for d in dates
        }
        for fut in concurrent.futures.as_completed(futures):
            url = fut.result()
            if url:
                print(f"ğŸ¯ æ‰¾åˆ° MP3ï¼ˆID:{song_id} æ—¥æœŸ:{futures[fut].date()}ï¼‰")
                return url, futures[fut]
    
    print(f"ğŸš« æœªæ‰¾åˆ° MP3ï¼ˆID:{song_id}ï¼‰")
    return None, base_date + timedelta(days=1)  # æ²¡æ‰¾åˆ°æ—¶æ—¥æœŸ+1å¤©

def process_batch(batch_ids, cur_date):
    """æ”¹è¿›çš„æ‰¹å¤„ç†å‡½æ•°ï¼ŒåŒ…å«æ™ºèƒ½å›æº¯"""
    success_count = 0
    last_success_date = cur_date
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        futures = [ex.submit(process_one, sid, cur_date) for sid in batch_ids]
        for fut in concurrent.futures.as_completed(futures):
            sid, nd = fut.result()
            if nd:  # å¦‚æœæˆåŠŸæ‰¾åˆ°MP3
                success_count += 1
                last_success_date = nd
            else:
                # å¤±è´¥æ—¶å°è¯•è°ƒæ•´æ—¥æœŸ
                if success_count > 0:
                    # å¦‚æœæœ‰æˆåŠŸè®°å½•ï¼Œä¿æŒå½“å‰æ—¥æœŸ
                    pass
                else:
                    # è¿ç»­å¤±è´¥ï¼Œè°ƒæ•´æ—¥æœŸ
                    days_to_add = random.randint(1, 3)
                    last_success_date += timedelta(days=days_to_add)
                    print(f"ğŸ”„ è°ƒæ•´æ—¥æœŸ +{days_to_add}å¤© ç”±äºè¿ç»­å¤±è´¥")
    
    # æ ¹æ®æˆåŠŸç‡åŠ¨æ€è°ƒæ•´æ—¥æœŸ
    success_rate = success_count / len(batch_ids)
    if success_rate < 0.3:  # å¦‚æœæˆåŠŸç‡ä½äº30%
        days_to_add = math.ceil((0.5 - success_rate) * 5)  # åŠ¨æ€è®¡ç®—è¦å¢åŠ çš„å¤©æ•°
        last_success_date += timedelta(days=days_to_add)
        print(f"ğŸ“ˆ ä½æˆåŠŸç‡({success_rate:.0%})ï¼Œè°ƒæ•´æ—¥æœŸ +{days_to_add}å¤©")
    
    return last_success_date

def main():
    # åŠ è½½è¿›åº¦æˆ–è‡ªåŠ¨æ¢æµ‹
    sid, cdate = load_progress()
    if sid is None or cdate is None:
        sid, cdate = auto_detect_start_params()
    
    print(f"ğŸš€ å¼€å§‹é‡‡é›†ï¼Œèµ·å§‹ ID: {sid}, èµ·å§‹æ—¥æœŸ: {cdate.date()}")

    stop_event = threading.Event()
    writer = threading.Thread(target=meta_writer_thread, args=(stop_event,), daemon=True)
    writer.start()

    try:
        consecutive_failures = 0
        while sid < END_ID:
            end = min(sid + BATCH_SIZE, END_ID)
            print(f"\nğŸ”„ æ‰¹æ¬¡é‡‡é›† ID {sid}â€“{end - 1}")
            
            cdate = process_batch(range(sid, end), cdate)
            save_progress(end, cdate)
            sid = end
            
            # åŠ¨æ€ç­‰å¾…æ—¶é—´ï¼ŒåŸºäºè¿ç»­å¤±è´¥æ¬¡æ•°
            if consecutive_failures > 3:
                wait_time = random.uniform(2, 5)
                print(f"âš ï¸ è¿ç»­å¤±è´¥{consecutive_failures}æ¬¡ï¼Œå»¶é•¿ç­‰å¾…æ—¶é—´è‡³{wait_time:.1f}s")
            else:
                wait_time = random.uniform(0.5, 1.5)
            print(f"â³ ç­‰å¾… {wait_time:.1f}s ç»§ç»­")
            time.sleep(wait_time)
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜è¿›åº¦...")
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
    finally:
        print("ğŸ›‘ ç­‰å¾…é˜Ÿåˆ—å†™å®Œæ•°æ®")
        meta_queue.join()
        stop_event.set()
        writer.join()
        session.close()
        print("ğŸ‰ é‡‡é›†ä»»åŠ¡ç»“æŸ")

if __name__ == "__main__":
    main()
