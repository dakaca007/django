import requests
from datetime import datetime, timedelta
import os
import time
import json
import random
from bs4 import BeautifulSoup, SoupStrainer
import concurrent.futures
from functools import lru_cache
import threading
import queue
import tempfile
import shutil

# é…ç½®é¡¹
START_ID = 1
END_ID = 1060020
INITIAL_DATE = datetime(2010, 3, 16)  # é»˜è®¤åˆå§‹æ—¥æœŸ
MAX_DATE_SHIFT = 7
PROGRESS_JSON = "progress.json"
FAILED_FILE = "failed.txt"
SONGS_META_FILE = "songs_meta.json"
BATCH_SIZE = 20
MAX_WORKERS = 5
MAX_RETRIES = 3

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
session = requests.Session()
session.headers.update(HEADERS)

# çº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œå­˜æ”¾å¾…å†™å…¥çš„å…ƒæ•°æ®
meta_queue = queue.Queue()

def brute_force_date(song_id, start_date, max_days=365 * 3):
    """æš´åŠ›æµ‹è¯•æ‰¾åˆ°IDå¯¹åº”çš„åˆç†æ—¥æœŸ"""
    base_url = "https://music.jsbaidu.com/upload/128"
    
    # å‘å‰æµ‹è¯•ï¼ˆæ—¥æœŸé€’å¢ï¼Œé€‚ç”¨äºæ›´å¤§çš„song_idï¼‰
    for i in range(max_days):
        test_date = start_date + timedelta(days=i)
        if test_date > datetime.now():
            continue
        url = f"{base_url}/{test_date:%Y/%m/%d}/{song_id}.mp3"
        try:
            r = session.head(url, timeout=2)
            if r.status_code == 200:
                print(f"ğŸ¯ æš´åŠ›æµ‹è¯•æˆåŠŸ (ID:{song_id} æ—¥æœŸ:{test_date.date()})")
                return test_date
        except:
            continue
    
    # å‘åæµ‹è¯•ï¼ˆæ—¥æœŸé€’å‡ï¼Œé€‚ç”¨äºæ›´å°çš„song_idï¼‰
    for i in range(max_days):
        test_date = start_date - timedelta(days=i)
        url = f"{base_url}/{test_date:%Y/%m/%d}/{song_id}.mp3"
        try:
            r = session.head(url, timeout=2)
            if r.status_code == 200:
                print(f"ğŸ¯ æš´åŠ›æµ‹è¯•æˆåŠŸ (ID:{song_id} æ—¥æœŸ:{test_date.date()})")
                return test_date
        except:
            continue
    
    print(f"âš ï¸ æš´åŠ›æµ‹è¯•å¤±è´¥ (ID:{song_id}) ä½¿ç”¨åˆå§‹æ—¥æœŸ")
    return start_date

def load_progress():
    """åŠ è½½è¿›åº¦ï¼Œè‡ªåŠ¨æ¢æµ‹æ—¥æœŸå…³ç³»"""
    if os.path.exists(PROGRESS_JSON):
        try:
            with open(PROGRESS_JSON, "r", encoding="utf-8") as f:
                data = json.load(f)
            sid = int(data.get("song_id", START_ID))
            
            # å°è¯•åŠ è½½ä¿å­˜çš„æ—¥æœŸ
            ldate_str = data.get("last_date")
            if ldate_str:
                try:
                    ldate = datetime.fromisoformat(ldate_str)
                    return sid, ldate
                except ValueError:
                    pass
        except Exception as e:
            print(f"âš ï¸ è¿›åº¦æ–‡ä»¶é”™è¯¯: {e}ï¼Œé‡æ–°æ¢æµ‹æ—¥æœŸ")
    
    # å¦‚æœæ²¡æœ‰è¿›åº¦æ–‡ä»¶æˆ–æ–‡ä»¶æŸåï¼Œæ‰§è¡Œæš´åŠ›æµ‹è¯•æ¢æµ‹æ—¥æœŸ
    print("ğŸ” æ— è¿›åº¦æ–‡ä»¶æˆ–æ–‡ä»¶æŸåï¼Œè‡ªåŠ¨æ¢æµ‹èµ·å§‹æ—¥æœŸ")
    detected_date = brute_force_date(START_ID, INITIAL_DATE)
    return START_ID, detected_date

def save_progress(song_id, last_date):
    try:
        with open(PROGRESS_JSON, "w", encoding="utf-8") as f:
            json.dump({
                "song_id": song_id,
                "last_date": last_date.date().isoformat()
            }, f)
    except Exception as e:
        print(f"âŒ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

def log_failure(song_id):
    try:
        with open(FAILED_FILE, "a", encoding="utf-8") as f:
            f.write(f"{song_id}\n")
    except Exception as e:
        print(f"âŒ è®°å½•å¤±è´¥IDå¤±è´¥: {e}")

def sanitize_filename(name):
    return "".join(c for c in name if c.isalnum() or c in (" ", "_", "-")).strip()

def retry(func, *args, **kw):
    """å¸¦é‡è¯•æœºåˆ¶çš„è¯·æ±‚åŒ…è£…å™¨"""
    for i in range(MAX_RETRIES):
        try:
            return func(*args, **kw)
        except Exception as e:
            if i == MAX_RETRIES - 1:
                print(f"âŒ æœ€ç»ˆå¤±è´¥ï¼š{e}")
                return None
            wait = random.uniform(1, 2 ** i)
            print(f"ğŸ” é‡è¯• {i+1}/{MAX_RETRIES}ï¼Œç­‰å¾… {wait:.1f}s")
            time.sleep(wait)

@lru_cache(maxsize=2048)
def extract_song_info(song_id):
    """æå–æ­Œæ›²å…ƒæ•°æ®"""
    def _():
        res = session.get(f"https://www.9ku.com/play/{song_id}.htm", timeout=5)
        if res.status_code != 200:
            return None
        strainer = SoupStrainer(["h1", "h2", "div", "textarea"])
        soup = BeautifulSoup(res.text, "html.parser", parse_only=strainer)
        title = soup.find("h1").text.strip() if soup.find("h1") else f"unknown_{song_id}"
        artist = soup.find("h2").text.strip() if soup.find("h2") else "unknown_artist"
        div = soup.find("div", class_="songText")
        release = album = None
        if div:
            for p in div.find_all("p", class_="p1"):
                t = p.get_text()
                if "å‘è¡Œæ—¶é—´ï¼š" in t: release = t.split("å‘è¡Œæ—¶é—´ï¼š")[1].split("&")[0].strip()
                if "æ‰€å±ä¸“è¾‘ï¼š" in t: album = p.find("a").text.strip() if p.find("a") else None
        lyric = soup.find("textarea", id="lrc_content")
        return {
            "song_id": song_id,
            "title": title,
            "artist": artist,
            "release_date": release,
            "album": album,
            "has_lyric": bool(lyric),
            "lyric_url": f"https://www.9ku.com/lyric/{song_id}.htm",  # æ–°å¢æ­Œè¯é¡µé¢åœ°å€
        }
    return retry(_)

def url_exists(url):
    """æ£€æŸ¥URLæ˜¯å¦å­˜åœ¨"""
    try:
        r = session.head(url, timeout=3)
        return url if r.status_code == 200 else None
    except:
        return None

def find_mp3_url(song_id, base_date):
    """å¯»æ‰¾MP3æ–‡ä»¶URL"""
    base = "https://music.jsbaidu.com/upload/128"
    dates = [base_date + timedelta(days=i) for i in range(MAX_DATE_SHIFT)]
    with concurrent.futures.ThreadPoolExecutor() as ex:
        futures = {
            ex.submit(url_exists, f"{base}/{d:%Y/%m/%d}/{song_id}.mp3"): d
            for d in dates
        }
        for fut in concurrent.futures.as_completed(futures):
            url = fut.result()
            if url:
                print(f"ğŸ¯ æ‰¾åˆ° MP3ï¼ˆID:{song_id} æ—¥æœŸ:{futures[fut].date()}ï¼‰")
                return url, futures[fut]
    print(f"ğŸš« æœªæ‰¾åˆ° MP3ï¼ˆID:{song_id}ï¼‰")
    return None, base_date

def safe_write_json(filename, data):
    """å®‰å…¨å†™å…¥JSONæ–‡ä»¶"""
    tmpfd, tmpname = tempfile.mkstemp(suffix=".tmp", prefix="tmp_")
    try:
        with os.fdopen(tmpfd, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        shutil.move(tmpname, filename)  # åŸå­æ›¿æ¢
    except Exception:
        if os.path.exists(tmpname):
            os.remove(tmpname)
        raise

def meta_writer_thread(stop_event):
    """åå°çº¿ç¨‹ï¼Œè´Ÿè´£å†™å…¥å…ƒæ•°æ®æ–‡ä»¶"""
    all_meta = []
    if os.path.exists(SONGS_META_FILE):
        try:
            with open(SONGS_META_FILE, "r", encoding="utf-8") as f:
                all_meta = json.load(f)
        except Exception:
            print("âš ï¸ æ— æ³•è¯»å–åŸæ­Œæ›²åˆ—è¡¨ï¼Œå†™å…¥æ–°æ–‡ä»¶")

    while not stop_event.is_set() or not meta_queue.empty():
        try:
            meta = meta_queue.get(timeout=1)
            all_meta.append(meta)
            safe_write_json(SONGS_META_FILE, all_meta)
            meta_queue.task_done()
        except queue.Empty:
            continue
        except Exception as e:
            print(f"âŒ å†™å…¥å…ƒæ•°æ®æ—¶å¼‚å¸¸: {e}")

def process_one(song_id, cur_date):
    """å¤„ç†å•ä¸ªæ­Œæ›²ID"""
    # å½“å¤„ç†æ–°IDæ—¶æ£€æŸ¥cur_dateæ˜¯å¦åˆç†
    test_url = f"https://music.jsbaidu.com/upload/128/{cur_date:%Y/%m/%d}/{song_id}.mp3"
    r = session.head(test_url, timeout=2)
    if r.status_code != 200:
        print(f"âš ï¸ æ—¥æœŸæ ¡å‡† {cur_date.date()} å¯èƒ½å·²è¿‡æœŸï¼Œé‡æ–°æ¢æµ‹")
        cur_date = brute_force_date(song_id, cur_date)

    info = extract_song_info(song_id)
    if not info:
        log_failure(song_id)
        return song_id, None

    mp3_url, new_date = find_mp3_url(song_id, cur_date)
    if not mp3_url:
        log_failure(song_id)
        return song_id, None

    filename = sanitize_filename(f"{info['title']}_{info['artist']}_{song_id}.mp3")

    meta_entry = {
        "song_id": song_id,
        "title": info['title'],
        "artist": info['artist'],
        "release_date": info.get('release_date'),
        "album": info.get('album'),
        "has_lyric": info['has_lyric'],
        "lyric_url": info['lyric_url'],  # ä¿å­˜æ­Œè¯åœ°å€
        "mp3_url": mp3_url,
        "filename": filename,
    }
    # æ”¾å…¥å†™é˜Ÿåˆ—ï¼Œç”±å†™çº¿ç¨‹å¼‚æ­¥å†™å…¥æ–‡ä»¶
    meta_queue.put(meta_entry)
    print(f"ğŸ“¦ å·²æ”¾å…¥å†™é˜Ÿåˆ—ï¼ˆID:{song_id}ï¼‰")

    return song_id, new_date

def process_batch(batch_ids, cur_date):
    """å¤„ç†ä¸€æ‰¹æ­Œæ›²ID"""
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        futures = [ex.submit(process_one, sid, cur_date) for sid in batch_ids]
        for fut in concurrent.futures.as_completed(futures):
            sid, nd = fut.result()
            if nd:
                cur_date = nd
            # è¿™é‡Œä¸åœ¨æ¯é¦–æ­Œä¿å­˜è¿›åº¦ï¼Œæ”¹æˆæ‰¹é‡åå†ä¿å­˜
    return cur_date

def main():
    sid, cdate = load_progress()
    print(f"ğŸš€ å¼€å§‹é‡‡é›†ï¼Œèµ·å§‹ ID: {sid}, èµ·å§‹æ—¥æœŸ: {cdate.date()}")

    stop_event = threading.Event()
    writer = threading.Thread(target=meta_writer_thread, args=(stop_event,), daemon=True)
    writer.start()

    try:
        while sid < END_ID:
            end = min(sid + BATCH_SIZE, END_ID)
            print(f"\nğŸ”„ æ‰¹æ¬¡é‡‡é›† ID {sid}â€“{end - 1}")
            cdate = process_batch(range(sid, end), cdate)
            save_progress(end, cdate)  # æ¯æ‰¹ç»“æŸåä¿å­˜è¿›åº¦
            sid = end
            dt = random.uniform(0.5, 1.5)
            print(f"â³ ç­‰å¾… {dt:.1f}s ç»§ç»­")
            time.sleep(dt)
    except KeyboardInterrupt:
        print("â›” ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜è¿›åº¦åé€€å‡º")
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
    finally:
        print("ğŸ›‘ ç­‰å¾…é˜Ÿåˆ—å†™å®Œæ•°æ®")
        meta_queue.join()
        stop_event.set()
        writer.join()

        print("ğŸ‰ æ‰€æœ‰é‡‡é›†ä»»åŠ¡å®Œæˆ")
        session.close()

if __name__ == "__main__":
    main()
